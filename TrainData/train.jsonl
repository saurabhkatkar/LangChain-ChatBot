{"id": "bd488e7e4462-0", "text": "embeddings operations.\nAugment ed data included with pr ompts . When using the \"on your data\" feature,\nthe service retrieves relevant data from a configured data store and augments the\nprompt to produce generations that are grounded with your data.\nTraining & v alidation data . You can provide your own training data consisting of\nprompt-completion pairs for the purposes of fine-tuning an OpenAI model .\nThe diagram below illustrates how your data is processed. This diagram covers three\ndifferent types of processing:\n1. How the Azure OpenAI Service processes your prompts to generate content\n(including when additional data from a connected data source is added to a\nprompt using Azure OpenAI on your data).\n2. How the Azure OpenAI Service creates a fine-tuned (custom) model with your\ntraining data.\n3. How the Azure OpenAI Service and Microsoft personnel analyze prompts,\ncompletions and images for harmful content and for patterns suggesting the use\nof the service in a manner that violates the Code of Conduct or other applicable\nproduct terms\nAs depicted in the diagram above, managed customers may apply to modify abuse\nmonitoring .How does the Azure OpenAI Service process\ndata?", "source": "SourceData\\DPS_Openai_Docs.pdf"}
{"id": "80c36771df0e-0", "text": "Models (base or fine-tuned) deployed in your resource process your input prompts and\ngenerate responses with text, images or embeddings. The service is configured to\nsynchronously evaluate the prompt and completion data in real time to check for\nharmful content types and stops generating content that exceeds the configured\nthresholds. Learn more at Azure OpenAI Service content filtering .\nThe models ar e stat eless: no pr ompts or generations ar e stored in the model.\nAdditionally , prompts and generations ar e not used t o train, r etrain, or impr ove the\nbase models.\nThe Azure OpenAI \"on your data\" feature lets you connect data sources to ground the\ngenerated results with your data. The data remains stored in the data source and\nlocation you designate. No data is copied int o the Azur e OpenAI ser vice. When a user\nprompt is received, the service retrieves relevant data from the connected data source\nand augments the prompt. The model processes this augmented prompt and the\ngenerated content is returned as described above.\nAs depicted in the diagram above, managed customers may apply to modify abuse\nmonitoring .\n fGenerating completions, images or embeddings\nAugmenting prompts with data retrieved from your data sources\nto \"ground\" the generated results\nCreating a customized (fine-tuned) model with your data:", "source": "SourceData\\DPS_Openai_Docs.pdf"}
{"id": "204f06379f97-0", "text": "Customers can upload their training data to the service to fine tune a model. Uploaded\ntraining data is stored in the Azure OpenAI resource in the customer\u2019s Azure tenant.\nTraining data and fine-tuned models:\nAre available exclusively for use by the customer.\nAre stored within the same region as the Azure OpenAI resource.\nCan be double encrypted at rest  (by default with Microsoft's AES-256 encryption\nand optionally with a customer managed key).\nCan be deleted by the customer at any time.\nTraining data uploaded for fine-tuning is not used to train, retrain, or improve any\nMicrosoft or 3rd party base models.\nTo reduce the risk of harmful use of the Azure OpenAI Service, the Azure OpenAI\nService includes both content filtering and abuse monitoring features. T o learn more\nabout content filtering , see Azure OpenAI Service content filtering. T o learn more about\nabuse monitoring, see abuse monitoring .\nContent filtering occurs synchronously as the service processes prompts to generate\ncontent as described above and here. No prompts or generated results are stored in the\ncontent classifier models, and prompts and results are not used to train, retrain, or\nimprove the classifier models.\nAzure OpenAI abuse monitoring detects and mitigates instances of recurring content\nand/or behaviors that suggest use of the service in a manner that may violate the code\nof conduct  or other applicable product terms. T o detect and mitigate abuse, Azure\nOpenAI stores all prompts and generated content securely for up to thirty (30) days.\n(No prompts or completions are stored if the customer is approved for and elects to\nconfigure abuse monitoring off, as described below.)\nThe data store where prompts and completions are stored is logically separated by\ncustomer resource (each request includes the resource ID of the customer\u2019s Azure\nOpenAI resource). A separate data store is located in each region  in which the Azure", "source": "SourceData\\DPS_Openai_Docs.pdf"}
{"id": "204f06379f97-1", "text": "OpenAI resource). A separate data store is located in each region  in which the Azure\nOpenAI Service is available, and a customer\u2019s prompts and generated content are\nstored in the Azure region where the customer\u2019s Azure OpenAI service resource is\ndeployed, within the Azure OpenAI service boundary. Human reviewers assessing\npotential abuse can access prompts and completions data only when that data has\nbeen flagged by the abuse monitoring system. The human reviewers are authorized\nMicrosoft employees who access the data via point wise queries using request IDs,\nSecure Access W orkstations (SA Ws), and Just-In-Time (JIT) request approval granted by\nteam managers. For Azure OpenAI Service deployed in the European Economic Area,Preventing abuse and harmful content generation", "source": "SourceData\\DPS_Openai_Docs.pdf"}
{"id": "3bea13b1ddc6-0", "text": "g p py p\nthe authorized Microsoft employees are located in the European Economic Area.\nSome customers may want to use the Azure OpenAI Service for a use case that involves\nthe processing of sensitive, highly confidential, or legally-regulated input data but\nwhere the likelihood of harmful outputs and/or misuse is low. These customers may\nconclude that they do not want or do not have the right to permit Microsoft to process\nsuch data for abuse detection, as described above, due to their internal policies or\napplicable legal regulations. T o address these concerns, Microsoft allows customers who\nmeet additional Limited Access eligibility criteria and attest to specific use cases to\napply to modify the Azure OpenAI content management features by completing this\nform .\nIf Microsoft approves a customer's request to modify abuse monitoring, then Microsoft\ndoes not store any prompts and completions associated with the approved Azure\nsubscription for which abuse monitoring is configured off. In this case, because no\nprompts and completions are stored at rest in the Service R esults S tore, the human\nreview process is not possible and is not performed. See Abuse monitoring  for more\ninformation.\nThere are two ways for customers, once approved to turn off abuse monitoring, to\nverify that data storage for abuse monitoring has been turned off in their approved\nAzure subscription:\nUsing the Azure portal, or\nAzure CLI (or any management API).\n1Si iAHow can customers get an exemption from\nabuse monitoring and human review?\nHow can a customer verify if data storage for abuse\nmonitoring is off?\n\uff17 Note\nThe value of \"false\" for the \"ContentLogging\" attribute appears only if data storage\nfor abuse monitoring is turned off. Otherwise, this property will not appear in\neither Azure portal or Azure CLI's output.\nPrerequisites", "source": "SourceData\\DPS_Openai_Docs.pdf"}
{"id": "ec6af6a7312c-0", "text": "1. Sign into Azure\n2. Select the Azure Subscription which hosts the Azure OpenAI Service resource.\n3. Navigate to the Overview  page of the Azure OpenAI Service resource.\nLogging status v erification using the Azur e por tal:\n1. Go to the resource Overview page\n2. Click on the JSON view  link on the top right corner as shown in the image below.\nThere will be a value in the Capabilities list called \"ContentLogging\" which will appear\nand be set to F ALSE when logging for abuse monitoring is off.\nJSON\nLogging status v erification using the Azur e CLI (or other management API):\nExecute the following command in Azure CLI to see the same JSON data as shown in\nthe Azure portal above.\nAzure CLI\nTo learn more about Microsoft's privacy and security commitments see the Microsoft\nTrust Center .{ \n    \"name\":\"ContentLogging\" ,\n    \"value\":\"false\"\n}\naz cognitiveservices account show -n resource\\_name -g resource \\_group", "source": "SourceData\\DPS_Openai_Docs.pdf"}
{"id": "97224761995e-0", "text": "Dat e Changes\n23\nJune\n2023Added information about data processing for new Azure on your data feature; removed\ninformation about abuse monitoring which is now available at Azure OpenAI Service\nabuse monitoring . Added summary note. Updated and streamlined content and\nupdated diagrams for additional clarity. added change log\nLimited access to Azure OpenAI Service\nCode of conduct for Azure OpenAI Service integrations\nTransparency note and use cases for Azure OpenAI Service\nCharacteristics and limitations for Azure OpenAI Service\nReport abuse of Azure OpenAI Service through the Report Abuse P ortal\nReport problematic content to cscraireport@microsoft.comChange log\nSee also", "source": "SourceData\\DPS_Openai_Docs.pdf"}
