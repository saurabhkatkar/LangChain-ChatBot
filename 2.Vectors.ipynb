{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    openai \\\n",
    "    \"pinecone-client[grpc]\"\\\n",
    "    langchain \\\n",
    "    tiktoken \\\n",
    "    sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: python-dotenv in /home/saurabh_katkar103/miniconda3/lib/python3.10/site-packages (1.0.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/saurabh_katkar103/miniconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/saurabh_katkar103/miniconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /home/saurabh_katkar103/miniconda3/lib/python3.10/site-packages (from pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/saurabh_katkar103/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.0.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "with open('TrainData/train.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        documents.append(json.loads(line))\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'bd488e7e4462-0',\n",
       " 'text': 'embeddings operations.\\nAugment ed data included with pr ompts . When using the \"on your data\" feature,\\nthe service retrieves relevant data from a configured data store and augments the\\nprompt to produce generations that are grounded with your data.\\nTraining & v alidation data . You can provide your own training data consisting of\\nprompt-completion pairs for the purposes of fine-tuning an OpenAI model .\\nThe diagram below illustrates how your data is processed. This diagram covers three\\ndifferent types of processing:\\n1. How the Azure OpenAI Service processes your prompts to generate content\\n(including when additional data from a connected data source is added to a\\nprompt using Azure OpenAI on your data).\\n2. How the Azure OpenAI Service creates a fine-tuned (custom) model with your\\ntraining data.\\n3. How the Azure OpenAI Service and Microsoft personnel analyze prompts,\\ncompletions and images for harmful content and for patterns suggesting the use\\nof the service in a manner that violates the Code of Conduct or other applicable\\nproduct terms\\nAs depicted in the diagram above, managed customers may apply to modify abuse\\nmonitoring .How does the Azure OpenAI Service process\\ndata?',\n",
       " 'source': 'SourceData\\\\DPS_Openai_Docs.pdf'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'langchain-retrieval-agent-sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh_katkar103/miniconda3/lib/python3.10/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import os\n",
    "\n",
    "# Load Pinecone API key\n",
    "api_key = os.getenv('PINECONE_API_KEY') or 'YOUR_API_KEY'\n",
    "# Set Pinecone environment. Find next to API key in console\n",
    "env = os.getenv('PINECONE_ENVIRONMENT') or \"YOUR_ENV\"\n",
    "\n",
    "pinecone.init(api_key=api_key, environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(index_name)\n",
    "\n",
    "# we create a new index\n",
    "pinecone.create_index(\n",
    "    name=index_name,\n",
    "    metric='cosine',\n",
    "    dimension=768  # 1536 dim of text-embedding-ada-002\n",
    ")\n",
    "\n",
    "# wait for index to be initialized\n",
    "while not pinecone.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.GRPCIndex(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "hf_embeddings = HuggingFaceEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id                                               text  \\\n",
      "0  bd488e7e4462-0  embeddings operations.\\nAugment ed data includ...   \n",
      "1  80c36771df0e-0  Models (base or fine-tuned) deployed in your r...   \n",
      "2  204f06379f97-0  Customers can upload their training data to th...   \n",
      "3  204f06379f97-1  OpenAI resource). A separate data store is loc...   \n",
      "4  3bea13b1ddc6-0  g p py p\\nthe authorized Microsoft employees a...   \n",
      "\n",
      "                           source  \n",
      "0  SourceData\\DPS_Openai_Docs.pdf  \n",
      "1  SourceData\\DPS_Openai_Docs.pdf  \n",
      "2  SourceData\\DPS_Openai_Docs.pdf  \n",
      "3  SourceData\\DPS_Openai_Docs.pdf  \n",
      "4  SourceData\\DPS_Openai_Docs.pdf   {'id': 'bd488e7e4462-0', 'text': 'embeddings operations.\\nAugment ed data included with pr ompts . When using the \"on your data\" feature,\\nthe service retrieves relevant data from a configured data store and augments the\\nprompt to produce generations that are grounded with your data.\\nTraining & v alidation data . You can provide your own training data consisting of\\nprompt-completion pairs for the purposes of fine-tuning an OpenAI model .\\nThe diagram below illustrates how your data is processed. This diagram covers three\\ndifferent types of processing:\\n1. How the Azure OpenAI Service processes your prompts to generate content\\n(including when additional data from a connected data source is added to a\\nprompt using Azure OpenAI on your data).\\n2. How the Azure OpenAI Service creates a fine-tuned (custom) model with your\\ntraining data.\\n3. How the Azure OpenAI Service and Microsoft personnel analyze prompts,\\ncompletions and images for harmful content and for patterns suggesting the use\\nof the service in a manner that violates the Code of Conduct or other applicable\\nproduct terms\\nAs depicted in the diagram above, managed customers may apply to modify abuse\\nmonitoring .How does the Azure OpenAI Service process\\ndata?', 'source': 'SourceData\\\\DPS_Openai_Docs.pdf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "data = pd.DataFrame(documents)\n",
    "print(data.head(),documents[0])\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    # get end of batch\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # first get metadata fields for this record\n",
    "    metadatas = [{\n",
    "        'id': record['id'],\n",
    "        'text': record['text']\n",
    "    } for j, record in batch.iterrows()]\n",
    "    # get the list of contexts / documents\n",
    "    docs = batch['text']\n",
    "    # create document embeddings\n",
    "    embeds = hf_embeddings.embed_documents(docs)\n",
    "    # get IDs\n",
    "    ids = batch['id']\n",
    "    # add everything to pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 7}},\n",
       " 'total_vector_count': 7}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, hf_embeddings.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='g p py p\\nthe authorized Microsoft employees are located in the European Economic Area.\\nSome customers may want to use the Azure OpenAI Service for a use case that involves\\nthe processing of sensitive, highly confidential, or legally-regulated input data but\\nwhere the likelihood of harmful outputs and/or misuse is low. These customers may\\nconclude that they do not want or do not have the right to permit Microsoft to process\\nsuch data for abuse detection, as described above, due to their internal policies or\\napplicable legal regulations. T o address these concerns, Microsoft allows customers who\\nmeet additional Limited Access eligibility criteria and attest to specific use cases to\\napply to modify the Azure OpenAI content management features by completing this\\nform .\\nIf Microsoft approves a customer\\'s request to modify abuse monitoring, then Microsoft\\ndoes not store any prompts and completions associated with the approved Azure\\nsubscription for which abuse monitoring is configured off. In this case, because no\\nprompts and completions are stored at rest in the Service R esults S tore, the human\\nreview process is not possible and is not performed. See Abuse monitoring  for more\\ninformation.\\nThere are two ways for customers, once approved to turn off abuse monitoring, to\\nverify that data storage for abuse monitoring has been turned off in their approved\\nAzure subscription:\\nUsing the Azure portal, or\\nAzure CLI (or any management API).\\n1Si iAHow can customers get an exemption from\\nabuse monitoring and human review?\\nHow can a customer verify if data storage for abuse\\nmonitoring is off?\\n７ Note\\nThe value of \"false\" for the \"ContentLogging\" attribute appears only if data storage\\nfor abuse monitoring is turned off. Otherwise, this property will not appear in\\neither Azure portal or Azure CLI\\'s output.\\nPrerequisites', metadata={'id': '3bea13b1ddc6-0'}),\n",
       " Document(page_content=\"Customers can upload their training data to the service to fine tune a model. Uploaded\\ntraining data is stored in the Azure OpenAI resource in the customer’s Azure tenant.\\nTraining data and fine-tuned models:\\nAre available exclusively for use by the customer.\\nAre stored within the same region as the Azure OpenAI resource.\\nCan be double encrypted at rest  (by default with Microsoft's AES-256 encryption\\nand optionally with a customer managed key).\\nCan be deleted by the customer at any time.\\nTraining data uploaded for fine-tuning is not used to train, retrain, or improve any\\nMicrosoft or 3rd party base models.\\nTo reduce the risk of harmful use of the Azure OpenAI Service, the Azure OpenAI\\nService includes both content filtering and abuse monitoring features. T o learn more\\nabout content filtering , see Azure OpenAI Service content filtering. T o learn more about\\nabuse monitoring, see abuse monitoring .\\nContent filtering occurs synchronously as the service processes prompts to generate\\ncontent as described above and here. No prompts or generated results are stored in the\\ncontent classifier models, and prompts and results are not used to train, retrain, or\\nimprove the classifier models.\\nAzure OpenAI abuse monitoring detects and mitigates instances of recurring content\\nand/or behaviors that suggest use of the service in a manner that may violate the code\\nof conduct  or other applicable product terms. T o detect and mitigate abuse, Azure\\nOpenAI stores all prompts and generated content securely for up to thirty (30) days.\\n(No prompts or completions are stored if the customer is approved for and elects to\\nconfigure abuse monitoring off, as described below.)\\nThe data store where prompts and completions are stored is logically separated by\\ncustomer resource (each request includes the resource ID of the customer’s Azure\\nOpenAI resource). A separate data store is located in each region  in which the Azure\", metadata={'id': '204f06379f97-0'}),\n",
       " Document(page_content='1. Sign into Azure\\n2. Select the Azure Subscription which hosts the Azure OpenAI Service resource.\\n3. Navigate to the Overview  page of the Azure OpenAI Service resource.\\nLogging status v erification using the Azur e por tal:\\n1. Go to the resource Overview page\\n2. Click on the JSON view  link on the top right corner as shown in the image below.\\nThere will be a value in the Capabilities list called \"ContentLogging\" which will appear\\nand be set to F ALSE when logging for abuse monitoring is off.\\nJSON\\nLogging status v erification using the Azur e CLI (or other management API):\\nExecute the following command in Azure CLI to see the same JSON data as shown in\\nthe Azure portal above.\\nAzure CLI\\nTo learn more about Microsoft\\'s privacy and security commitments see the Microsoft\\nTrust Center .{ \\n    \"name\":\"ContentLogging\" ,\\n    \"value\":\"false\"\\n}\\naz cognitiveservices account show -n resource\\\\_name -g resource \\\\_group', metadata={'id': 'ec6af6a7312c-0'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How can customers get an exemption from abuse monitoring and human review\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
